# **<u>Nerual Networ From Scratch</u>**
## project Overview
The project serves as a practical demonstration of my theoretical understanding of the foundations of Neural Networks and their underlying mechanics.
Every layer, loss or activation function, optimization algorithm, gradient computation, and model in general - was made with no libraries implementation uses.
The mathematical computations were carried out manually, utilizing NumPy arrays only for convenience in handling calculations.
Additionally, you'll find several unused functions, such as variations of SGD, included to provide a glimpse into my experimental process during the project's development.
The project's primary goal is to build a classification model for a synthetic dataset with varying input dimensions and outputs. It employs a CrossEntropy loss function and supports both traditional fully connected (FC) layers and residual FC layers.
